

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text-As-Treatment &mdash; GPI: GenAI-Powered Inference 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=320156fd" />

  
    <link rel="shortcut icon" href="_static/gpi.png"/>
    <link rel="canonical" href="https://gpi-pack.github.io/tarnet.html" />
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=01f34227"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/js/copybutton.js?v=a2f921dd"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Text-As-Confounder" href="text_as_confounder.html" />
    <link rel="prev" title="Generating Images with Diffusion Models" href="gen_diffusion.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="index.html" class="icon icon-home">
            GPI: GenAI-Powered Inference
              <img src="_static/logo_long.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-pypi">From PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-source">From Source</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpi.html">What’s GPI?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#generative-ai-powered-inference">Generative-AI Powered Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="startgpu.html">How to use GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#what-s-gpu">What’s GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#what-if-you-do-not-have-gpu">What if you do not have GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#id1">Google Colaboratory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="report.html">Questions and Bug Reports</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Generation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gen_llama.html">Generating Texts with LLaMa3</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#how-to-use-llama3">How to use LLaMa3</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#creating-texts">Creating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#repeating-texts">Repeating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#system-prompt">System Prompt</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen_llm.html">Generating Texts with Other LLMs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llm.html#example-gemma2">Example: Gemma2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen_nnsight.html">Generating Texts without GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_nnsight.html#nnsight-for-gpi">NNsight for GPI</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen_diffusion.html">Generating Images with Diffusion Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_diffusion.html#what-is-diffusion-model">What is diffusion model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_diffusion.html#how-to-use-stable-diffusion">How to use Stable Diffusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_diffusion.html#arguments">Arguments</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Operation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text-As-Treatment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-text-as-treatment">What is Text-As-Treatment?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-estimate-treatment-effects">How to estimate treatment effects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-load-the-internal-representations">Step 1: Load the Internal Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-estimate-the-treatment-effects">Step 2: Estimate the Treatment Effects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-control-confounders">How to control confounders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#method-1-using-a-formula-with-a-dataframe">Method 1: Using a Formula with a DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="#method-2-using-a-design-matrix">Method 2: Using a Design Matrix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#visualizing-propensity-scores">Visualizing Propensity Scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hyperparameters">Hyperparameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="text_as_confounder.html">Text-As-Confounder</a><ul>
<li class="toctree-l2"><a class="reference internal" href="text_as_confounder.html#what-is-text-as-confounder">What is Text-As-Confounder?</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_as_confounder.html#how-to-estimate-treatment-effects">How to estimate treatment effects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="image_as_treatment.html">Image-As-Treatment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="image_as_treatment.html#how-to-estimate-treatment-effects">How to estimate treatment effects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="image_as_treatment.html#step-1-load-the-internal-representations">Step 1: Load the Internal Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="image_as_treatment.html#step-2-estimate-the-treatment-effects">Step 2: Estimate the Treatment Effects</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Operations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter.html">Hyperparameter Tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#automated-hyperparameter-tuning">Automated Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#list-of-hyperparameters">List of Hyperparameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_imp.html">Customizing Your Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#tarnet">TarNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#propensity-score-model">Propensity Score Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#estimation-workflow">Estimation Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">When LLM is too big</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quantization.html#model-quantization">Model Quantization</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="f_dml_score.html">dml_score</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_k_ate.html">estimate_k_ate</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_psi_split.html">estimate_psi_split</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_extract_and_save_hiddens.html">extract_and_save_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_generate_text.html">generate_text</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_get_instructions.html">get_instruction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_load_hiddens.html">load_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_save_generated_texts.html">save_generated_texts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_SpectralNormClassifier.html">SpectralNormClassifier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict-proba">predict_proba</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet_loss.html">TarNet_loss</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet.html">TarNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetBase.html">TarNetBase</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#arguments">Arguments:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetHyperparameterTuner.html">TarNetHyperparameterTuner</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#description">Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#example-usage">Example Usage</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GPI: GenAI-Powered Inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Text-As-Treatment</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="text-as-treatment">
<span id="ref-textastreatment"></span><h1>Text-As-Treatment<a class="headerlink" href="#text-as-treatment" title="Link to this heading"></a></h1>
<p>Text-As-Treatment is a key setting where <strong>gpi_pack</strong> is especially useful. Instead of directly modeling texts, we use the internal representations of LLMs to estimate treatment effects. This approach improves accuracy and computational efficiency. In this section, we provide an overview of the Text-As-Treatment setting and demonstrate how to use gpi_pack to estimate treatment effects with the internal representations of LLMs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This part is based on our paper <a class="reference external" href="https://arxiv.org/abs/2410.00903">Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments</a>. Please refer to the paper for the technical details.</p>
</div>
<section id="what-is-text-as-treatment">
<h2>What is Text-As-Treatment?<a class="headerlink" href="#what-is-text-as-treatment" title="Link to this heading"></a></h2>
<p>Text-As-Treatment refers to scenarios where participants receive various texts, and the goal is to determine how one specific feature of the texts (e.g., topics or sentiments) influences downstream outcomes. A primary challenge in this setting is that texts inherently contain other features that might confound the relationship between the feature of interest and the outcome.</p>
<p>To address this challenge, <a class="reference external" href="https://arxiv.org/abs/2410.00903">our paper</a> proposes using LLMs’ internal representations to bypass the direct modeling of texts. We introduce a representation learning method called  <strong>deconfounder</strong>, which enables us to estimate the treatment effects of the feature of interest without directly observing all confounding features. The deconfounder is estimated using <cite>TarNet</cite>, which takes the internal representations as input and predicts outcomes under both treatment and control conditions using a shared deconfounder. The following figure illustrates the architecture of <cite>TarNet</cite>:</p>
<a class="reference internal image-reference" href="_images/tarnet.png"><img alt="TarNet architecture" class="align-center" src="_images/tarnet.png" style="width: 600px;" />
</a>
<p>Once the deconfounder and the outcome models are estimated, a propensity score model is built based on the deconfounder. Finally, the estimated outcome models and propensity score model are used together with double machine learning techniques to estimate treatment effects.</p>
</section>
<section id="how-to-estimate-treatment-effects">
<h2>How to estimate treatment effects<a class="headerlink" href="#how-to-estimate-treatment-effects" title="Link to this heading"></a></h2>
<p><strong>gpi_pack</strong> offers the wrapper function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to streamline the estimation of treatment effects using LLMs’ internal representations. This function handles all the necessary steps, including deconfounder estimation and propensity score estimation, so you only need to provide the data.</p>
<p>Suppose you have a DataFrame <code class="docutils literal notranslate"><span class="pre">df</span></code> containing the treatment variable, outcome variable, and texts, and you have already extracted the internal representations of the LLMs (saved as .pt files). Below is an example demonstrating how to use <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> .</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading required packages</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># create a data frame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;TreatmentVar&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;OutcomeVar&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;Text&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;Create a biography of an American politician named Nathaniel C. Gilchrist&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named John Doe&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Jane Smith&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Mary Johnson&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Robert Brown&#39;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">})</span>
</pre></div>
</div>
<section id="step-1-load-the-internal-representations">
<h3>Step 1: Load the Internal Representations<a class="headerlink" href="#step-1-load-the-internal-representations" title="Link to this heading"></a></h3>
<p>First, load the internal representations using the <code class="docutils literal notranslate"><span class="pre">load_hiddens</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading required packages</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gpi_pack.TarNet</span><span class="w"> </span><span class="kn">import</span> <span class="n">estimate_k_ate</span><span class="p">,</span> <span class="n">load_hiddens</span>

<span class="c1"># load hidden states stored as .pt files</span>
<span class="n">hidden_dir</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">YOUR</span><span class="o">-</span><span class="n">DIRECTORY</span><span class="o">&gt;</span> <span class="c1"># directory containing hidden states (e.g., &quot;hidden_last_1.pt&quot; for text indexed 1)</span>

<span class="n">hidden_states</span> <span class="o">=</span> <span class="n">load_hiddens</span><span class="p">(</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">hidden_dir</span><span class="p">,</span>
    <span class="n">hidden_list</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="c1"># list of indices for hidden states</span>
    <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;hidden_last_&quot;</span><span class="p">,</span> <span class="c1"># prefix of hidden states (e.g., &quot;hidden_last_&quot; for &quot;hidden_last_1.pt&quot;)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you have not extracted internal representation, please refer to the section <a class="reference internal" href="gen_llama.html#generate-texts"><span class="std std-ref">Generating Texts with LLaMa3</span></a>.</p>
</div>
</section>
<section id="step-2-estimate-the-treatment-effects">
<h3>Step 2: Estimate the Treatment Effects<a class="headerlink" href="#step-2-estimate-the-treatment-effects" title="Link to this heading"></a></h3>
<p>Once the internal representations are loaded, use <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># estimate treatment effects</span>
<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="c1"># Data (Inputs)</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>

    <span class="c1"># Hyperparameters (optional)</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1">#outcome model architecture</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span> <span class="c1">#deconfounder architecture</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To compute a 95% confidence interval for the treatment effect estimate, use the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate 95% confidence interval</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">ate</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">ate</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ATE: </span><span class="si">{</span><span class="n">ate</span><span class="si">}</span><span class="s2">, SE: </span><span class="si">{</span><span class="n">se</span><span class="si">}</span><span class="s2">, 95% CI: (</span><span class="si">{</span><span class="n">lower_bound</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">upper_bound</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="c1"># ATE: 0.5, SE: 0.1, 95% CI: (0.3, 0.7)</span>
</pre></div>
</div>
</section>
</section>
<section id="how-to-control-confounders">
<h2>How to control confounders<a class="headerlink" href="#how-to-control-confounders" title="Link to this heading"></a></h2>
<p>In some cases, you may want to control for confounders that are not included in the texts. <strong>gpi_pack</strong> supports this via the <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> function in two ways:</p>
<section id="method-1-using-a-formula-with-a-dataframe">
<h3>Method 1: Using a Formula with a DataFrame<a class="headerlink" href="#method-1-using-a-formula-with-a-dataframe" title="Link to this heading"></a></h3>
<p>If your DataFrame includes confounders as columns, specify a formula (e.g., <code class="docutils literal notranslate"><span class="pre">formula_c</span> <span class="pre">=</span> <span class="pre">&quot;conf1</span> <span class="pre">+</span> <span class="pre">conf2&quot;</span></code>) along with the DataFrame in the function call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Method 1: supply covariates with a formula and DataFrame</span>
<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">formula_c</span><span class="o">=</span><span class="s2">&quot;conf1 + conf2&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>
    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>

    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>

    <span class="c1">#Deconfounder model architecture:</span>
    <span class="c1"># [2048] means that the input (hidden states) is passed to the intermediate layer with size 2048.</span>
    <span class="c1"># The size of last layer (last number in the list) corresponds to the dimension of the deconfounder.</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="method-2-using-a-design-matrix">
<h3>Method 2: Using a Design Matrix<a class="headerlink" href="#method-2-using-a-design-matrix" title="Link to this heading"></a></h3>
<p>Alternatively, create a design matrix of confounders and pass it to the <code class="docutils literal notranslate"><span class="pre">C</span></code> argument:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The design matrix should be a NumPy array or a list of values.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Method 2: supply covariates using a design matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span> <span class="c1">#load numpy module</span>
<span class="n">C_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;conf1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;conf2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="n">C_mat</span><span class="p">,</span> <span class="c1">#design matrix of confounding variable</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>

    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>

    <span class="c1">#Deconfounder model architecture:</span>
    <span class="c1"># [2048] means that the input (hidden states) is passed to the intermediate layer with size 2048.</span>
    <span class="c1"># The size of last layer (last number in the list) corresponds to the dimension of the deconfounder.</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="visualizing-propensity-scores">
<h2>Visualizing Propensity Scores<a class="headerlink" href="#visualizing-propensity-scores" title="Link to this heading"></a></h2>
<p>For the Text-As-Treatment setting, it is crucial to assume that the textual feature and the confounding features are disentangled—a property known as <strong>separability</strong>. Visualizing the propensity scores can help diagnose whether this assumption holds. If the propensity scores are extreme (close to 0 or 1), it may indicate that confounding features are entangled with the treatment feature of interest.</p>
<p>By default, the <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> function allows you to visualize the propensity scores by setting <code class="docutils literal notranslate"><span class="pre">plot_propensity=True</span></code>. Below is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># estimate treatment effects</span>
<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1">#outcome model architecture</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span> <span class="c1">#deconfounder architecture</span>
    <span class="n">plot_propensity</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="c1">#visualize propensity scores</span>
<span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/propensity.png"><img alt="propensity score" src="_images/propensity.png" style="width: 600px;" />
</a>
</section>
<section id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> function accepts the following parameters:</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">R</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of hidden states extracted from LLM. Shape: (N, d_R) where N is the number of samples and d_R is the dimension of hidden states. You can load the stored hidden states using <cite>load_hiddens</cite> function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Y</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of outcomes, shape: (N,).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">T</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of treatments, shape: (N,). Typically binary (0 or 1).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">C</span></code>: list or np.ndarray, optional</dt><dd><p>A matrix of additional confounders, shape: (N, d_C). If provided, these will be concatenated to R along axis=1. You can pass either this parameter directly or use <cite>formula_c</cite> and <cite>data</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">formula_c</span></code>: str, optional</dt><dd><p>A Patsy-style formula (e.g., <cite>“conf1 + conf2”</cite>) that specifies how to build the confounder matrix from a DataFrame. If this is provided, <cite>data</cite> must also be provided, and <cite>C</cite> will be constructed via <cite>dmatrix(formula_c, data)</cite>. Intercept is removed from the design matrix.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">data</span></code>: pandas.DataFrame, optional</dt><dd><p>The DataFrame containing the columns used in <cite>formula_c</cite>. If <cite>formula_c</cite> is set, this parameter is required. The resulting design matrix is then concatenated to R as additional confounders.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">K</span></code>: int, default=2</dt><dd><p>Number of cross-fitting folds (K-fold split).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">valid_perc</span></code>: float, default=0.2</dt><dd><p>Proportion of the training set to use for validation when fitting TarNet in each fold.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">plot_propensity</span></code>: bool, default=True</dt><dd><p>Whether to plot the propensity score distribution in the console or a graphing interface (implementation-specific).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ps_model</span></code>: object, optional</dt><dd><p>A model/classifier used to estimate the propensity score. By default, we use a neural network with Spectral Normalization (to ensure Lipshitz continuity).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ps_model_params</span></code>: dict, optional</dt><dd><p>Hyperparameters for <cite>ps_model</cite>. For example, <cite>{“input_dim”: 2048}</cite> if using a custom model requiring an input dimension.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: int, default=32</dt><dd><p>Batch size for TarNet training.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">nepoch</span></code>: int, default=200</dt><dd><p>Number of epochs to train TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">step_size</span></code>: int, optional</dt><dd><p>Step size for the learning rate scheduler (if applicable).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">lr</span></code>: float, default=2e-5</dt><dd><p>Learning rate for TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">dropout</span></code>: float, default=0.2</dt><dd><p>Dropout rate for TarNet layers.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">architecture_y</span></code>: list, default=[200, 1]</dt><dd><p>List specifying the layer sizes for the outcome heads (treatment-specific networks or final layers). For example, [200, 1] means that the outcome model has two hidden layers, the first with 200 units and the second with 1 unit.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">architecture_z</span></code>: list, default=[2048]</dt><dd><p>List specifying the layer sizes for the deconfounder. For example, [2048, 2048] means that the deconfounder has two hidden layers, each with 2048 units.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">trim</span></code>: list, default=[0.01, 0.99]</dt><dd><p>Trimming bounds for the propensity score. Propensity scores outside this range will be replaced with the nearest bound.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">bn</span></code>: bool, default=False</dt><dd><p>Whether to apply batch normalization in TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">patience</span></code>: int, default=5</dt><dd><p>Patience for early stopping in TarNet training (number of epochs without improvement).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">min_delta</span></code>: float, default=0</dt><dd><p>Minimum improvement threshold for early stopping.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">model_dir</span></code>: str, optional</dt><dd><p>Directory path where the model checkpoints might be saved. If provided, the best model will be saved here and loaded for predictions.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: bool, default=True</dt><dd><p>Whether to print additional information during training.</p>
</dd>
</dl>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gen_diffusion.html" class="btn btn-neutral float-left" title="Generating Images with Diffusion Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="text_as_confounder.html" class="btn btn-neutral float-right" title="Text-As-Confounder" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Kentaro Nakamura, Kosuke Imai.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>