<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to use GPU &mdash; GPI: GenAI-Powered Inference 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=320156fd" />

  
    <link rel="canonical" href="https://gpi-pack.github.io/startgpu.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=01f34227"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="_static/js/copybutton.js?v=a2f921dd"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Generating Texts with LLaMa3" href="gen_llama.html" />
    <link rel="prev" title="What’s GPI?" href="gpi.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="index.html" class="icon icon-home">
            GPI: GenAI-Powered Inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-pypi">From PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-source">From Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#requirements">Requirements</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpi.html">What’s GPI?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#generative-ai-powered-inference">Generative-AI Powered Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#contribute-to-gpi">Contribute to GPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to use GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-s-gpu">What’s GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-if-you-do-not-have-gpu">What if you do not have GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">Google Colaboratory</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Generation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gen_llama.html">Generating Texts with LLaMa3</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#how-to-use-llama3">How to use LLaMa3</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#creating-texts">Creating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#repeating-texts">Repeating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#system-prompts">System Prompts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen_llm.html">Generating Texts with Other LLMs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llm.html#example-gemma2">Example: Gemma2</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Operation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tarnet.html">Text-As-Treatment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tarnet.html#what-is-text-as-treatment">What is Text-As-Treatment?</a></li>
<li class="toctree-l2"><a class="reference internal" href="tarnet.html#how-to-estimate-treatment-effects">How to estimate treatment effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="tarnet.html#how-to-control-confounders">How to control confounders</a></li>
<li class="toctree-l2"><a class="reference internal" href="tarnet.html#visualizing-propensity-scores">Visualizing Propensity Scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="tarnet.html#hyperparameters">Hyperparameters</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Operations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter.html">Hyperparameter Tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#automated-hyperparameter-tuning">Automated Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#list-of-hyperparameters">List of Hyperparameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_imp.html">Customizing Your Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#tarnet">TarNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#propensity-score-model">Propensity Score Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#estimation-workflow">Estimation Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">When LLM is too big</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quantization.html#model-quantization">Model Quantization</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="f_dml_score.html">dml_score</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_k_ate.html">estimate_k_ate</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#purpose-and-description">Purpose and Description:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#arguments">Arguments:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#returns">Returns:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#example-usage">Example Usage:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_psi_split.html">estimate_psi_split</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_extract_and_save_hiddens.html">extract_and_save_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_generate_text.html">generate_text</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_get_instructions.html">get_instruction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_load_hiddens.html">load_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_save_generated_texts.html">save_generated_texts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_SpectralNormClassifier.html">SpectralNormClassifier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict-proba">predict_proba</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet_loss.html">TarNet_loss</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet.html">TarNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetBase.html">TarNetBase</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#arguments">Arguments:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetHyperparameterTuner.html">TarNetHyperparameterTuner</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#purpose-and-description">Purpose and Description:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#example-usage">Example Usage:</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GPI: GenAI-Powered Inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">How to use GPU</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-use-gpu">
<span id="gpu-usage-section"></span><h1>How to use GPU<a class="headerlink" href="#how-to-use-gpu" title="Link to this heading"></a></h1>
<p><strong>gpi_pack</strong> is built upon PyTorch, which is a popular deep learning framework that supports GPU acceleration. The use of GPU is not essential for the statistical inference, but to use LLM to extract the hidden states, you must need to use GPU. The GPU can significantly speed up the computation of the model, especially for large models and datasets.</p>
<section id="what-s-gpu">
<h2>What’s GPU?<a class="headerlink" href="#what-s-gpu" title="Link to this heading"></a></h2>
<p>GPU (Graphics Processing Unit) is a specialized hardware designed to accelerate the computation of deep learning models. You need to install the GPU driver and CUDA toolkit to use GPU.</p>
<p>The easy way to check the availability of GPU is to run the following command in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
</pre></div>
</div>
<p>If the output is <code class="docutils literal notranslate"><span class="pre">True</span></code>, you can use GPU. If the output is <code class="docutils literal notranslate"><span class="pre">False</span></code> but your machine has GPU, you need to install the GPU driver and CUDA toolkit. You can find the instructions for installing the GPU driver and CUDA toolkit on <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/">the NVIDIA website</a>.</p>
</section>
<section id="what-if-you-do-not-have-gpu">
<h2>What if you do not have GPU?<a class="headerlink" href="#what-if-you-do-not-have-gpu" title="Link to this heading"></a></h2>
<p>In many cases, your laptop or desktop does not have GPU. In that case, you can use the cloud service such as <a class="reference external" href="https://colab.research.google.com/">Google Colaboratory</a> or <a class="reference external" href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a>. These services provide a virtual environment with GPU support, and you can use them to run your code. Below I show how to use Google Colaboratory.</p>
</section>
<section id="id1">
<h2>Google Colaboratory<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>Google Colaboratory is a free cloud service that provides a virtual environment with GPU support. You can use it to run your code without installing anything on your local machine. To use Google Colaboratory, you need to have a Google account.</p>
<ol class="arabic simple">
<li><p>Go to <a class="reference external" href="https://colab.research.google.com/">Google Colaboratory</a> and sign in with your Google account.</p></li>
<li><p>Create a new notebook by clicking on the “New Notebook” button. In the notebook, you can write and run Python code just like you would on your local machine.</p></li>
<li><p>To use GPU, you need to enable it by clicking on the “Runtime” button and selecting “Change runtime type”. Then, select “GPU (e.g., T4GPU, A100 GPU)” You can now run your code on the GPU.</p></li>
</ol>
<a class="reference internal image-reference" href="_images/google_cloud.gif"><img alt="Screenshot of Google Colaboratory" src="_images/google_cloud.gif" style="width: 600px;" /></a>
<ol class="arabic simple" start="4">
<li><p>To install <strong>gpi_pack</strong> on Google Colaboratory, you can use the following command (you can run this directly on the notebook):</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!pip<span class="w"> </span>install<span class="w"> </span>gpi_pack
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>To connect your Google Colaboratory notebook to your Google Drive, you need to run the following command:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gpi.html" class="btn btn-neutral float-left" title="What’s GPI?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="gen_llama.html" class="btn btn-neutral float-right" title="Generating Texts with LLaMa3" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Kentaro Nakamura, Kosuke Imai.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>