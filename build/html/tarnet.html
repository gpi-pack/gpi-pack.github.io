<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Text-As-Treatment &mdash; GPI: GenAI-Powered Inference 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=320156fd" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=01f34227"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="_static/js/copybutton.js?v=a2f921dd"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hyperparameter Tuning" href="hyperparameter.html" />
    <link rel="prev" title="Generating Texts with Other LLMs" href="gen_llm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="index.html" class="icon icon-home">
            GPI: GenAI-Powered Inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-pypi">From PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#from-source">From Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#requirements">Requirements</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gpi.html">What’s GPI?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#generative-ai-powered-inference">Generative-AI Powered Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpi.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="startgpu.html">How to use GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#what-s-gpu">What’s GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#what-if-you-do-not-have-gpu">What if you do not have GPU?</a></li>
<li class="toctree-l2"><a class="reference internal" href="startgpu.html#id1">Google Colaboratory</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Generation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gen_llama.html">Generating Texts with LLaMa3</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#how-to-use-llama3">How to use LLaMa3</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#creating-texts">Creating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#repeating-texts">Repeating Texts</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="gen_llama.html#system-prompts">System Prompts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gen_llm.html">Generating Texts with Other LLMs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gen_llm.html#example-gemma2">Example: Gemma2</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Basic Operation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text-As-Treatment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-is-text-as-treatment">What is Text-As-Treatment?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-estimate-treatment-effects">How to estimate treatment effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-control-confounders">How to control confounders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#visualizing-propensity-scores">Visualizing Propensity Scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hyperparameters">Hyperparameters</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Operations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter.html">Hyperparameter Tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#automated-hyperparameter-tuning">Automated Hyperparameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="hyperparameter.html#list-of-hyperparameters">List of Hyperparameters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="custom_imp.html">Customizing Your Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#tarnet">TarNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#propensity-score-model">Propensity Score Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_imp.html#estimation-workflow">Estimation Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">When LLM is too big</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quantization.html#model-quantization">Model Quantization</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="f_dml_score.html">dml_score</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_dml_score.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_k_ate.html">estimate_k_ate</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#purpose-and-description">Purpose and Description:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#arguments">Arguments:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#returns">Returns:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_k_ate.html#example-usage">Example Usage:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_estimate_psi_split.html">estimate_psi_split</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_estimate_psi_split.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_extract_and_save_hiddens.html">extract_and_save_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_extract_and_save_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_generate_text.html">generate_text</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_generate_text.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_get_instructions.html">get_instruction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_get_instructions.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_load_hiddens.html">load_hiddens</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_load_hiddens.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_save_generated_texts.html">save_generated_texts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_save_generated_texts.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_SpectralNormClassifier.html">SpectralNormClassifier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_SpectralNormClassifier.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict-proba">predict_proba</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_SpectralNormClassifier.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet_loss.html">TarNet_loss</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#returns">Returns</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet_loss.html#example-usage">Example Usage</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNet.html">TarNet</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNet.html#methods">Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#fit">fit</a></li>
<li class="toctree-l3"><a class="reference internal" href="f_TarNet.html#predict">predict</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetBase.html">TarNetBase</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#purpose-and-description">Purpose and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#example-usage">Example Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetBase.html#arguments">Arguments:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="f_TarNetHyperparameterTuner.html">TarNetHyperparameterTuner</a><ul>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#purpose-and-description">Purpose and Description:</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#arguments">Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="f_TarNetHyperparameterTuner.html#example-usage">Example Usage:</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GPI: GenAI-Powered Inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Text-As-Treatment</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="text-as-treatment">
<span id="ref-textastreatment"></span><h1>Text-As-Treatment<a class="headerlink" href="#text-as-treatment" title="Link to this heading"></a></h1>
<p>Text-As-Treatment is one of the most important settings where <strong>gpi-pack</strong> is useful. Instead of modeling the texts directly, we use the internal representation of the LLMs to estimate the treatment effects. By avoiding the direct modeling of the texts, we can achieve the accurate and more computationally efficient estimation of the treatment effects. This section provides the overview of the Text-As-Treatment setting and how to use <strong>gpi-pack</strong> to estimate the treatment effects using the internal representation of the LLMs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This part is based on our paper <a class="reference external" href="https://arxiv.org/abs/2410.00903">Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments</a>. Please refer to the paper for the technical details.</p>
</div>
<section id="what-is-text-as-treatment">
<h2>What is Text-As-Treatment?<a class="headerlink" href="#what-is-text-as-treatment" title="Link to this heading"></a></h2>
<p>Text-As-Treatment refers to the setting where many texts are assigned to the participants and we are interested in how one specific feature (e.g., topics, sentiments) of texts influences the downstream outcomes. The key challenge in this setting is that texts contain some other featrues that might confound the relationship between the feature of interest and the outcome.</p>
<p>To address this challenge, <a class="reference external" href="https://arxiv.org/abs/2410.00903">our paper</a> proposes to use the internal representation of the LLMs to avoid the modeling of the texts, and we devised the representation learning method called <strong>deconfounder</strong>, by which we can estimate the treatment effects of the feature of interest without directly observing all the confounding features. Deconfounder is estimated using <cite>TarNet</cite>, which inputs the internal representation and predict the outcome under the treatment and control conditions using the shared <strong>deconfounder</strong>. The following figure shows the architecture of <cite>TarNet</cite>.</p>
<a class="reference internal image-reference" href="_images/tarnet.png"><img alt="TarNet architecture" src="_images/tarnet.png" style="width: 600px;" /></a>
<p>Once we estimate the <strong>deconfoudner</strong> and the outcome models, we estimate the propensity score model based on the estimated deconfounder. Finally, we use the estimated outcome models and the propensity score model to estimate the treatment effects using the double machine learning techniques.</p>
</section>
<section id="how-to-estimate-treatment-effects">
<h2>How to estimate treatment effects<a class="headerlink" href="#how-to-estimate-treatment-effects" title="Link to this heading"></a></h2>
<p><strong>gpi_pack</strong> provides the wrapper function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects using the internal representation of the LLMs. This function internally handles all the estimation procedures including deconfounder estimation and propensity score estimations, and you only need to specify the data. Below is the example of how to use <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects.</p>
<p>Suppose that we have the following data frame <code class="docutils literal notranslate"><span class="pre">df</span></code> that contains the treatment variable, outcome variable, and the texts, and we already extracted the internal representation of the LLMs and saved them as .pt files.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading required packages</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># create a data frame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;TreatmentVar&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;OutcomeVar&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;Text&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;Create a biography of an American politician named Nathaniel C. Gilchrist&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named John Doe&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Jane Smith&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Mary Johnson&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Create a biography of an American politician named Robert Brown&#39;</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">})</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you have not extracted internal representation, please refer to the section <a class="reference internal" href="gen_llama.html#generate-texts"><span class="std std-ref">Generating Texts with LLaMa3</span></a>.</p>
</div>
<p>Firstly, you need to load the internal representation of the LLMs. You can use the function <code class="docutils literal notranslate"><span class="pre">load_hiddens</span></code> to load the internal representation of the LLMs. The following is an example of how to use <code class="docutils literal notranslate"><span class="pre">load_hiddens</span></code> to load the internal representation of the LLMs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading required packages</span>
<span class="kn">from</span> <span class="nn">gpi_pack.TarNet</span> <span class="kn">import</span> <span class="n">estimate_k_ate</span><span class="p">,</span> <span class="n">load_hiddens</span>

<span class="c1"># load hidden states stored as .pt files</span>
<span class="n">hidden_dir</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">YOUR</span><span class="o">-</span><span class="n">DIRECTORY</span><span class="o">&gt;</span> <span class="c1"># directory containing hidden states (e.g., &quot;hidden_last_1.pt&quot; for text indexed 1)</span>

<span class="n">hidden_states</span> <span class="o">=</span> <span class="n">load_hiddens</span><span class="p">(</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">hidden_dir</span><span class="p">,</span>
    <span class="n">hidden_list</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="c1"># list of indices for hidden states</span>
    <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;hidden_last_&quot;</span><span class="p">,</span> <span class="c1"># prefix of hidden states (e.g., &quot;hidden_last_&quot; for &quot;hidden_last_1.pt&quot;)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Once you load the internal representation of the LLMs, you can use the function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects. The following is an example of how to use <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects.</p>
<p>Theoretically, the estimator follows the normal distribution when the sample size is large enough. Therefore, we can use the following code to calculate the 95% confidence interval of the treatment effects.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate 95% confidence interval</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">ate</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">ate</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">se</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ATE: </span><span class="si">{</span><span class="n">ate</span><span class="si">}</span><span class="s2">, SE: </span><span class="si">{</span><span class="n">se</span><span class="si">}</span><span class="s2">, 95% CI: (</span><span class="si">{</span><span class="n">lower_bound</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">upper_bound</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="c1"># ATE: 0.5, SE: 0.1, 95% CI: (0.3, 0.7)</span>
</pre></div>
</div>
</section>
<section id="how-to-control-confounders">
<h2>How to control confounders<a class="headerlink" href="#how-to-control-confounders" title="Link to this heading"></a></h2>
<p>Sometimes, we want to control the confounders that are not included in the texts. In this case, we can use the function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects while controlling the confounders. The following is an example of how to use <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> to estimate the treatment effects while controlling the confounders.</p>
<p>There are two ways to control the confounders. One is to use the formula and the <code class="docutils literal notranslate"><span class="pre">pandas</span></code> data frame. To do this, your data frame must contain the confounders as columns, and you need to specify the formula of confounders (<code class="docutils literal notranslate"><span class="pre">formula_c</span> <span class="pre">=</span> <span class="pre">&quot;conf1</span> <span class="pre">+</span> <span class="pre">conf2&quot;</span></code>) and the data frame (<code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">df</span></code>) in the function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Method 1: supply covariates with a formula and DataFrame</span>
<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">formula_c</span><span class="o">=</span><span class="s2">&quot;conf1 + conf2&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>
    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>

    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>

    <span class="c1">#Deconfounder model architecture:</span>
    <span class="c1"># [2048] means that the input (hidden states) is passed to the intermediate layer with size 2048.</span>
    <span class="c1"># The size of last layer (last number in the list) corresponds to the dimension of the deconfounder.</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The other way is to use the design matrix of confounders. To do this, you need to create a design matrix of confounders and specify it in the <code class="docutils literal notranslate"><span class="pre">C</span></code> argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Method 2: supply covariates using a design matrix</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1">#load numpy module</span>
<span class="n">C_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;conf1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;conf2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">C</span><span class="o">=</span><span class="n">C_mat</span><span class="p">,</span> <span class="c1">#design matrix of confounding variable</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>

    <span class="c1">#Outcome model architecture</span>
    <span class="c1"># [100, 1] means that the deconfounder is passed to the intermediate layer with size 100,</span>
    <span class="c1"># and then it passes to the output layer with size 1.</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>

    <span class="c1">#Deconfounder model architecture:</span>
    <span class="c1"># [2048] means that the input (hidden states) is passed to the intermediate layer with size 2048.</span>
    <span class="c1"># The size of last layer (last number in the list) corresponds to the dimension of the deconfounder.</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="visualizing-propensity-scores">
<h2>Visualizing Propensity Scores<a class="headerlink" href="#visualizing-propensity-scores" title="Link to this heading"></a></h2>
<p>For Text-As-Treatment, we need to assume that textual feature and confounding features are disentangled. This assumption is called <strong>separability</strong>, and this can be directly diagnosed by visualizing the propensity scores. For this reason, we recommend users to visualize the propensity scores to check if the separability is not violated. If the propensity score shows the extreme values (0 or 1), it is likely that some confounding features are entangled with the treatment feature of interest.</p>
<p>Our function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> provides the option to visualize the propensity scores. To visualize the propensity scores, you need to set <code class="docutils literal notranslate"><span class="pre">plot_propensity</span> <span class="pre">=</span> <span class="pre">True</span></code> in the function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> (which is the default option). The following is an example of how to visualize the propensity scores.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># estimate treatment effects</span>
<span class="n">ate</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">estimate_k_ate</span><span class="p">(</span>
    <span class="n">R</span><span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;OutcomeVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">T</span><span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TreatmentVar&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="c1">#K-fold cross-fitting</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-5</span><span class="p">,</span> <span class="c1">#learning rate</span>
    <span class="n">architecture_y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="c1">#outcome model architecture</span>
    <span class="n">architecture_z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2048</span><span class="p">],</span> <span class="c1">#deconfounder architecture</span>
    <span class="n">plot_propensity</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="c1">#visualize propensity scores</span>
<span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/propensity.png"><img alt="propensity score" src="_images/propensity.png" style="width: 600px;" /></a>
</section>
<section id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Link to this heading"></a></h2>
<p>The function <code class="docutils literal notranslate"><span class="pre">estimate_k_ate</span></code> has the following parameters.</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">R</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of hidden states extracted from LLM. Shape: (N, d_R) where N is the number of samples and d_R is the dimension of hidden states. You can load the stored hidden states using <cite>load_hiddens</cite> function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">Y</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of outcomes, shape: (N,).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">T</span></code>: list or np.ndarray</dt><dd><p>A list or NumPy array of treatments, shape: (N,). Typically binary (0 or 1).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">C</span></code>: list or np.ndarray, optional</dt><dd><p>A matrix of additional confounders, shape: (N, d_C). If provided, these will be concatenated to R along axis=1. You can pass either this parameter directly or use <cite>formula_c</cite> and <cite>data</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">formula_c</span></code>: str, optional</dt><dd><p>A Patsy-style formula (e.g., <cite>“conf1 + conf2”</cite>) that specifies how to build the confounder matrix from a DataFrame. If this is provided, <cite>data</cite> must also be provided, and <cite>C</cite> will be constructed via <cite>dmatrix(formula_c, data)</cite>. Intercept is removed from the design matrix.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">data</span></code>: pandas.DataFrame, optional</dt><dd><p>The DataFrame containing the columns used in <cite>formula_c</cite>. If <cite>formula_c</cite> is set, this parameter is required. The resulting design matrix is then concatenated to R as additional confounders.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">K</span></code>: int, default=2</dt><dd><p>Number of cross-fitting folds (K-fold split).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">valid_perc</span></code>: float, default=0.2</dt><dd><p>Proportion of the training set to use for validation when fitting TarNet in each fold.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">plot_propensity</span></code>: bool, default=True</dt><dd><p>Whether to plot the propensity score distribution in the console or a graphing interface (implementation-specific).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ps_model</span></code>: object, optional</dt><dd><p>A model/classifier used to estimate the propensity score. By default, we use a neural network with Spectral Normalization (to ensure Lipshitz continuity).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">ps_model_params</span></code>: dict, optional</dt><dd><p>Hyperparameters for <cite>ps_model</cite>. For example, <cite>{“input_dim”: 2048}</cite> if using a custom model requiring an input dimension.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: int, default=32</dt><dd><p>Batch size for TarNet training.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">nepoch</span></code>: int, default=200</dt><dd><p>Number of epochs to train TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">step_size</span></code>: int, optional</dt><dd><p>Step size for the learning rate scheduler (if applicable).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">lr</span></code>: float, default=2e-5</dt><dd><p>Learning rate for TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">dropout</span></code>: float, default=0.2</dt><dd><p>Dropout rate for TarNet layers.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">architecture_y</span></code>: list, default=[200, 1]</dt><dd><p>List specifying the layer sizes for the outcome heads (treatment-specific networks or final layers). For example, [200, 1] means that the outcome model has two hidden layers, the first with 200 units and the second with 1 unit.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">architecture_z</span></code>: list, default=[2048]</dt><dd><p>List specifying the layer sizes for the deconfounder. For example, [2048, 2048] means that the deconfounder has two hidden layers, each with 2048 units.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">trim</span></code>: list, default=[0.01, 0.99]</dt><dd><p>Trimming bounds for the propensity score. Propensity scores outside this range will be replaced with the nearest bound.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">bn</span></code>: bool, default=False</dt><dd><p>Whether to apply batch normalization in TarNet.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">patience</span></code>: int, default=5</dt><dd><p>Patience for early stopping in TarNet training (number of epochs without improvement).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">min_delta</span></code>: float, default=0</dt><dd><p>Minimum improvement threshold for early stopping.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">model_dir</span></code>: str, optional</dt><dd><p>Directory path where the model checkpoints might be saved. If provided, the best model will be saved here and loaded for predictions.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: bool, default=True</dt><dd><p>Whether to print additional information during training.</p>
</dd>
</dl>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="gen_llm.html" class="btn btn-neutral float-left" title="Generating Texts with Other LLMs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hyperparameter.html" class="btn btn-neutral float-right" title="Hyperparameter Tuning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Kentaro Nakamura, Kosuke Imai.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>